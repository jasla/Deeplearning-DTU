@article{Sajda,
abstract = {In this paper a constrained non-negative matrix factorization (cNMF) algorithm for recovering constituent spectra is described together with experiments demonstrating the broad utility of the approach. The algorithm is based on the NMF algorithm of Lee and Seung, 1, 2 extending it to include a constraint on the minimum amplitude of the recovered spectra. This constraint enables the algorithm to deal with observations having negative values by assuming they arise from the noise distribution. The cNMF algorithm does not explicitly enforce independence or sparsity, instead only requiring the source and mixing matrices to be non-negative. The algorithm is very fast compared to other " blind " methods for recovering spectra. 3, 4 cNMF can be viewed as a maximum likelihood approach for finding basis vectors in a bounded subspace. In this case the optimal basis vectors are the ones that envelope the observed data with a minimum deviation from the boundaries. Results for Raman spectral data, hyperspectral images, and 31 P human brain data are provided to illustrate the algorithm's performance.},
author = {Sajda, Paul and Du, Shuyan and Parra, Lucas},
file = {::},
keywords = {Non},
title = {{Recovery of constituent spectra using non-negative matrix factorization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.868{\&}rep=rep1{\&}type=pdf}
}
@inproceedings{Alstrom2017,
author = {Alstrom, Tommy S. and Schmidt, Mikkel N. and Rindzevicius, Tomas and Boisen, Anja and Larsen, Jan},
booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2017.7952570},
isbn = {978-1-5090-4117-6},
month = {mar},
pages = {2317--2321},
publisher = {IEEE},
title = {{A pseudo-Voigt component model for high-resolution recovery of constituent spectra in Raman spectroscopy}},
url = {http://ieeexplore.ieee.org/document/7952570/},
year = {2017}
}
@article{Wei2013,
author = {Wei, Hong and Xu, Hongxing},
doi = {10.1039/c3nr02924g},
file = {::},
issn = {2040-3364},
journal = {Nanoscale},
month = {oct},
number = {22},
pages = {10794},
publisher = {Royal Society of Chemistry},
title = {{Hot spots in different metal nanostructures for plasmon-enhanced Raman spectroscopy}},
url = {http://xlink.rsc.org/?DOI=c3nr02924g},
volume = {5},
year = {2013}
}
@article{Langville2014,
abstract = {It is well known that good initializations can improve the speed and accuracy of the solutions of many nonnegative matrix factorization (NMF) algorithms. Many NMF algorithms are sensitive with respect to the initialization of W or H or both. This is especially true of algorithms of the alternating least squares (ALS) type, including the two new ALS algorithms that we present in this paper. We compare the results of six initialization procedures (two standard and four new) on our ALS algorithms. Lastly, we discuss the practical issue of choosing an appropriate convergence criterion.},
archivePrefix = {arXiv},
arxivId = {1407.7299},
author = {Langville, Amy N. and Meyer, Carl D. and Albright, Russell and Cox, James and Duling, David},
eprint = {1407.7299},
file = {:C$\backslash$:/Users/jakob/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Langville et al. - 2014 - Algorithms, Initializations, and Convergence for the Nonnegative Matrix Factorization.pdf:pdf},
month = {jul},
title = {{Algorithms, Initializations, and Convergence for the Nonnegative Matrix Factorization}},
url = {http://arxiv.org/abs/1407.7299},
year = {2014}
}
@article{Vincent,
abstract = {Previous work has shown that the difficul-ties in learning deep generative or discrim-inative models can be overcome by an ini-tial unsupervised learning step that maps in-puts to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a rep-resentation based on the idea of making the learned representations robust to partial cor-ruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to ini-tialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising ad-vantage of corrupting the input of autoen-coders on a pattern classification benchmark suite.},
author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
file = {:C$\backslash$:/Users/jakob/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vincent et al. - Unknown - Extracting and Composing Robust Features with Denoising Autoencoders.pdf:pdf},
title = {{Extracting and Composing Robust Features with Denoising Autoencoders}},
url = {http://www.cs.toronto.edu/{~}larocheh/publications/icml-2008-denoising-autoencoders.pdf}
}
@misc{Dempster1977,
abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
booktitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
doi = {10.2307/2984875},
pages = {1--38},
publisher = {WileyRoyal Statistical Society},
title = {{Maximum Likelihood from Incomplete Data via the EM Algorithm}},
url = {https://www.jstor.org/stable/2984875},
volume = {39},
year = {1977}
}
@article{Seung1999,
abstract = {Learning the parts of objects by non-negative matrix factorization},
author = {Seung, H. Sebastian and Lee, Daniel D.},
doi = {10.1038/44565},
file = {::},
issn = {00280836},
journal = {Nature},
month = {oct},
number = {6755},
pages = {788--791},
publisher = {Nature Publishing Group},
title = {{Learning the parts of objects by non-negative matrix factorization}},
url = {http://www.nature.com/doifinder/10.1038/44565},
volume = {401},
year = {1999}
}
@article{Hosseini-Asl2016,
author = {Hosseini-Asl, Ehsan and Zurada, Jacek M. and Nasraoui, Olfa},
doi = {10.1109/TNNLS.2015.2479223},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
month = {dec},
number = {12},
pages = {2486--2498},
title = {{Deep Learning of Part-Based Representation of Data Using Sparse Autoencoders With Nonnegativity Constraints}},
url = {http://ieeexplore.ieee.org/document/7310882/},
volume = {27},
year = {2016}
}
@InProceedings{snmf2006,
author = {Schmidt, Mikkel N. and Olsson, Rasmus K.},
title = {Single-Channel Speech Separation using Sparse Non-Negative Matrix},
booktitle = {Interspeech 2006 and 9th International Conference on Spoken Language Processing, Interspeech 2006},
pages = {2614-2617},
year = {2006}
}

@InProceedings{ramanSNMF2014,
author = {Alstrøm, Tommy S. and Frøhling, Kasper B. and Larsen, Jan and Schmidt, Mikkel N. and Bache, Michael and Schmidt, Michael S. and Jakobsen, Mogens H. and Boisen, Anja},
title = {Improving the Robustness of Surface Enhanced Raman Spectroscopy Based Sensors by Bayesian Non-Negative Matrix Factorization},
booktitle = {2014 IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING, SEPT. 21–24, 2014, REIMS, FRANCE},
OPTcrossref = {•},
OPTkey = {•},
OPTpages = {•},
year = {2014},
OPTeditor = {•},
OPTvolume = {•},
OPTnumber = {•},
OPTseries = {•},
OPTaddress = {•},
OPTmonth = {•},
OPTorganization = {•},
publisher = {IEEE},
OPTnote = {•},
OPTannote = {•}
}